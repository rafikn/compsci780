\section{Methodology}
We now describe the algorithm used to simulated an obfuscated boolean circuit and the tools used to measure its evaluation impact on a hardware platform.
\subsection{BPW Generation} 
Thomborson proposed a space-efficient and computationally-appropriate file format (BPW) for the evaluation of very large Boolean functions with bounded program widths\cite{clark}. Gates of a circuit are represented by descriptors holding information about their type (AND, OR, $\dots$) and are sequentially encoded inside the file's body. In our experiment we generate random boolean circuits (which evaluates a random boolean function) with varying width $w = \{ 10^3, 10^4, 10^5, 10^6, 10^7, 10^8\}$ for a fixed circuit size $N = 10^8$. The relationship between a circuit width and depth is $ N = w \times D $, so for $ w = N$ the circuit has depth 1.
\par
The generated circuits are represented using a simplified BPW format by storing the gate type and the input indices only and by making some assumptions about the properties of the circuit under test. In particular, we make the following assumptions about the size of the circuit's inputs and outputs as well as the manner outputs from level $L_i$ are passed to gates in level $L_{i+1}$ as inputs.
\begin{enumerate}  
\item All circuits have size $N = 10^8$
\item A circuit input array has size $w$.
\item Any given level $L$ has exactly $w$ gates.
\item Every gate has only one output.
\item A circuit output array has size $w$.
\item Any given gate from a level $L_i$ has between one and three inputs that come from level $L_{i-1}$ exclusively, such that:\break $G_i = f(X)$, where $f$ is a boolean operator and $X$ is an 8-byte array of size 1, 2 or 3. 
\item The output of a gate is written inside the output array at the same index of the gate. $G_i(X) = Output$ $array[i]$.
\end{enumerate}
The \textit{rand()} method from the \textit{C} standard library was used to attribute a random type to a gate, as well as assign its input indices.

\subsection{Evaluation}
A circuit evaluation is sequential at both gate and layer level. During execution, gates of a level $L_i$ are processed in ascending order of index in the level. Inputs indices for a gate are randomly distributed over [0, $w$-1]. Every gate retrieves its relevant inputs as described by the gate descriptor. Once a gate is processed, its output is stored in the output array at the same index as the gate. Once all the gates of level $L_i$ are processed, the execution cursor moves to level $L_{i+1}$. The random distribution of gate input indices will significantly affect the overall performance of the circuit for large $w$, as the entire input array cannot fit in the cache. Figure \ref{fig:level} describes how a level is evaluated.
\begin{figure}[h]
	\center
	\includegraphics[width=0.8\textwidth]{img/level.png}
	\caption{Simple description of Level $L_i$ evaluation}
	\label{fig:level}
\end{figure}
\par
\subsection{Hardware}
Obfuscators might occasionally run on super computers, however it is likely that viable commercial use of obfuscators would require them to run on mass market platforms such as smart phones, battery powered laptops and desktop computers\cite{clark}. The target platform for the circuits evaluation is a mid-level desktop computer. The CPU is a 64-bits-instruction-set 	 with a base frequency of 3.40 GHz (Max of 4.1GHz). It has 4 cores that can run a thread each and has the following cache capacities (in bytes): 
\begin{itemize}[noitemsep]
\item Level 1 data cache: 32K
\item Level 1 instruction cache: 32K
\item Level 2 cache: 256K
\item Level 3 cache: 6144K
\end{itemize}
We predict that having a circuit with a width higher than the capacity of the last-level cache is a perfect candidate to observe an impact on performance.
\par
The operating system used is Linux Fedora 22 on kernel 4.4.5.


\subsection{Metrics}
The \textit{perf} linux command was used to measure the impact of evaluating a circuit on the CPU. \textit{perf} is a tool written in \text{C} that uses Performance Counters to profile an application\footnote{\url{https://github.com/torvalds/linux/tree/master/tools/perf}}. Performance counters are CPU hardware registers that count hardware events such as instructions executed, cache-misses suffered, or branches mispredicted\cite{perfwiki}. The \textit{perf} tool has the advantage of being program oriented, instead of system oriented \cite{ibm}.   In particular, the \textit{perf stat} subcommand allows to retrieval event counts that are of interest to our experiment. These metrics are mainly \textit{instructions, cycles} and \textit{LLC-loads}. 
\begin{itemize}
\item \textbf{instructions} are unitary operations executed by the CPU at the lowest level such ADD, SUB, LOAD or STORE. They can represent arithmetic operations, data handling operations or control flow operations. Modern CPUs include more complex instructions for complicated integer or float point operations.
\item \textbf{cycles} are the steps performed by the CPU when it recieves an instruction. Typically early processors would pipeline fetching the instruction from the program counter, decoding it, reading its associated variables from the registers, executing its logic order and finally writing the result back to registers or storing it the system's main memory\cite{jmor}. After an initial set up time, pipelining allows to execute one instruction per cycle, assuming no stalls. Modern CPUs achieve more than on instruction per cycle using techniques like \textit{Instruction-level Parallelism} (loading more than one instruction in the pipeline) and \textit{out-of-order execution} (allowing the simultaneous execution of multiple instructions that don't depend on each other for input or output). The Intel Core i5 can handle up to 4 instructions per clock cycle\cite{agner}, but this figure is usually lower because of stalls, i.e.\ when the pipeline is waiting for the result of a previous instruction before proceeding.

\item \textbf{LLC-loads} are instructions to load results from the Last-Level of Cache (or L3) of the CPU. L3 cache is the largest and highest-latency level of cache for the Intel Core i5 CPU. It is shared amongst all its cores.

\end{itemize}
For every value of $w$, we configure \textit{perf} to run the experiment 3 times and collect the arithmetic average of the event counters.


\section{Simulation Results}
In this section we present the results of our experiment.
\par
We suggest that the total running time of a circuit follows the analytical model:
\begin{equation}
T = \max\{ t_g + t_e, t_m(w) \}
\end{equation}
where $T$ is the total elapsed (wallclock) time in processing a single gate, $t_g$ is the CPU time for generating a gate, $t_e$ is the CPU time for evaluating a gate, and $t_m(w)$ are the memory-stalls from the gate-generation and gate-evaluation computations.
\par
In our experiment, we generate the entire circuit prior to its evaluation. $t_g$ is in fact related to the time cost of loading of the gate for execution. We assume that this time component is near constant per gate and is not affected by the width $w$. The generation step executed initially is therefore not monitored for performance. The resulting circuit is stacked gate by gate in a simplified BPW file. Following the initial BPW format developed by Thomborson, the first 4 bytes represent the header of the a BPW file\cite{clark}. The following bytes then represent the total gates of the circuit. All gates are sequentially represented from index $0$ to index $10^8-1$. A given gate's encoding varies from 9 to 25 bytes. The first byte holds the type of the gate. The following 8 to 24 bytes present the input indices encoded over 64-bits each. The gate's representation could be optimised to the minimum bytes needed to encode a gate. Compression could also be used to save disk space. We chose to keep the existing model for simplicity. As mentioned earlier, the size of the circuits under test was fixed to $N = 10^8$. The average size of a BPW file storing a circuit is therefore $avg(sizeof(Gate)) * 10^8 \approx 2 GB$ \footnote{We modelled 14 types of Gates; 1 $\times$ 1-input, 6 $\times$ 2-input and 7 $\times$ 3-input gates. On average, a gate has 2.43 inputs encoded with 8 bytes per input plus one byte for the gate type.}.

\begin{table}[]
\centering
\begin{tabular}{|l|l|l|l|}
\hline
w                 & $10^3$       & $10^4$       & $10^5$       \\ \hline
task-clock (ms)   & 13116.554712 & 13322.905953 & 13313.335011 \\ \hline
instructions      & 99200423097  & 97602445259  & 97553743526  \\ \hline
cycles            & 55393862507  & 56255744084  & 56207517444  \\ \hline
instruction/cycle & 1.74         & 1.76         & 1.74         \\ \hline
branches          & 17179168771  & 16896966649  & 16887492840  \\ \hline
branch-misses     & 213275235    & 267635214    & 267596585    \\ \hline
LLC-loads         & 75319029     & 75177952     & 78311853     \\ \hline
std deviation     & 1.49\%       & 0.94\%       & 0.27\%       \\ \hline
\end{tabular}
\caption{Simulation results for $ w \in \{10^3, 10^4, 10^5\}$ }
\label{tab:res1}
\end{table}


\begin{table}[h]
\centering
\begin{tabular}{|l|l|l|l|}
\hline
w                 & $10^6$      & $10^7$      & $10^8$       \\ \hline
task-clock (ms)   & 13633.97763 & 16041.15891 & 17507.07431  \\ \hline
instructions      & 97578653791 & 98201779911 & 103646369628 \\ \hline
cycles            & 57584456723 & 67736311966 & 73941409511  \\ \hline
instruction/cycle & 1.69        & 1.44        & 1.4          \\ \hline
branches          & 16897296695 & 17058902603 & 18501020880  \\ \hline
branch-misses     & 266970610   & 266910904   & 268274635    \\ \hline
LLC-loads         & 328139283   & 380853849   & 505923626    \\ \hline
std deviation     & 0.43\%      & 0.50\%      & 0.19\%       \\ \hline
\end{tabular}%
\caption{Simulation results for $ w \in \{10^6, 10^7, 10^8\}$}
\label{tab:res2}
\end{table}


\par
From the results collected in tables \ref{tab:res1} and \ref{tab:res2} we established the following:

\[ T =
  \begin{cases}
    t_g + t_e       & \quad \text{if } \log_{10}(w) < 7\\
    t_m(w) & \quad \text{if } \log_{10}(w) > 7\\
  \end{cases}
\]

We estimate that $t_m(w)$ for $w = 10^3$ is negligible. In our experiment $E(w = 10^6)$ the total run time is assumed to reflect load and execution operations only (with no width penalty) which establishes $t_g + t_e \approx 130\text{ ns}$.\footnote{ For $w = 10^3, N=10^8$, we have $N \times T = 13116 \text{ms} \implies T \approx 130 \text{ns}$ }. 
Since the CPU has a frequency of 3.40 GHz the load and execution of a gate require about 450 CPU cycles per gate\footnote{$130 \times 10^{-9} \times 3.4 \times 10^9 = 442$}, which is up to 2000 instruction per cycle (at 1.7 instructions per cycle) on a quad-core CPU assuming no stalls. For all tested $w < 10^7$ we observed a stable instruction per cycle rate at 1.7 ins/cycle with 0.2 instruction per cycle stalled.
\par
For $ w > 10^7$ the computation becomes memory-bound, allowing us to estimate $t_m(10^7) = 162$ns and $t_m(10^8) = 176$ns. Since we used 6 types of 2-input gate and 7 types of 3-input gate (out of a total 14 gate types), a gate evaluation will have 1 fetch to read the gate type and about 2.5 memory-fetches on average to read its inputs. The gate evaluation process will also write the result in the output buffer which will cause additional memory writes. 
\par
Once the gate is unpacked in a top-level \textit{C} \textbf{struct} of 16 bytes (1 byte for the type, 8 bytes for the input pointer, before padding to the largest power of 2), with 2.5 input indices of 8 bytes each, a level needs $ (16 + 2.5 \times 8) \times w $ of memory to be fully represented, e.g.\ levels for $w = 10^7$ need 3.6 GB. This amount of memory cannot obviously reside in cache, and on 4 GB memory platforms there would certainly be page-faults requiring hard disk activity. We estimate that the level array can fit inside our system's 16GB RAM without disk faults. Our initial algorithm loads an entire level before feeding into the execution loop. We could improve this by evaluating a gate as soon as it is loaded.  
\par
We designed the gate inputs to be spread randomly in an array of width $w$. For any large enough $w$, the CPU last level cache (LLC) will miss with a high probability when the input bit-array cannot be fully contained. On our test platform, LLC is 6MB wide and the cache line is 64B\cite{agnor}. 
\par
For $w = 10^7$, the input array occupies $8 \times 10^7$ bits, the miss rate should be $1 - (6\times10^6B/10^7B) = 40\%$. From the observed $T = 162ns$ we deduce the memory latency, which is the time required by the CPU to fetch a gate input from the cache, to be $162ns$ per LLC miss.\footnote{ $latency = \frac{T}{2.5 \times \text{miss rate}}$ where $T$ is the total run time per gate}. Each unpacked level occupies $ 36\times10^7$ bytes in memory. For the observed run time this is equivalent to 225 MB/s in memory bandwidth. The reported LLC-loads represent about 10\% for the bandwidth at 23.5 MB/s. However, the cache line being 64B wide, the LLC-loads represent 1.3 GB/s bandwidth. With the estimated latency, there should be a a gate input miss every 162ns. This gives us a bandwidth of 453 MB. We suspect that the 900 MB difference noted is possibly due to the read and write traffic caused by the writing of the results back into the output array.
\par
The Ivy Bridge CPU family, to which our test CPU belongs, also seems to have a problem with the pre-fetch instructions wasting time on pre-fetching data that are already in the cache\cite{agnor} which might explain the high bandwidth observed.
\par
\begin{table}[]
\centering
\begin{tabular}{|c|c|c|c|}
\hline
width  & time/Gate (ns) & LLC-loads/Gate & instructions/Gate \\ \hline
$10^8$ & 175.0707431    & 5.05923626     & 1036.463696       \\ \hline
$10^7$ & 160.4115891    & 3.80853849     & 982.0177991       \\ \hline
$10^6$ & 136.3397763    & 3.28139283     & 975.7865379       \\ \hline
$10^5$ & 133.1333501    & 0.78311853     & 975.5374353       \\ \hline
$10^4$ & 133.2290595    & 0.75177952     & 976.0244526       \\ \hline
$10^3$ & 131.1655471    & 0.75319029     & 992.004231        \\ \hline
\end{tabular}
\caption{Simulation results per Gate}
\label{tab:fig3}
\end{table}
Based on the data on this paper, we could not observe significant hit on the overall performance when evaluating wide circuits. This might be explained by the CPU's successful speculative optimisation of branch mispredictions. We also suspect that the generation of random 64-bit input indices using the C \textit{rand()} method (which returns a random 32-bit integer) might produce numbers with the most significant bits 75\% biased towards 1\footnote{\url{http://stackoverflow.com/questions/4945698/is-the-value-of-rand-max-always-2n-1}}
. This will affect the memory-fetch statistics for gates with large indices.
\par
However, as shown in \ref{tab:fig3}, we did notice an increase in the total time of execution per gate around the $w = 10^6$ mark. The LLC-load rate was almost constant for $w < 10^5 $ at 0.75 load per gate but then jumped 5 loads per gate for $w = 10^8$.
